{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import root_config as rc #this is needed to resolve the local modules\n",
    "rc.configure()\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "from detectdd.config import *\n",
    "from detectdd.auth_bigquery import BigQueryClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    mimic_drugs = f\"\"\"\n",
    "        SELECT itemid, label, abbreviation, category, unitname\n",
    "        FROM {icu_d_items}\n",
    "        WHERE linksto='inputevents' \"\"\"\n",
    "\n",
    "    mimic_job = BigQueryClient.auth().query(mimic_drugs)\n",
    "    df = mimic_job.to_dataframe()\n",
    "    df.label = df.label.fillna(\"\")\n",
    "    df.label = df.label.apply(str.lower)\n",
    "    return df\n",
    "\n",
    "icu_drugs = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_drugs():\n",
    "    df = pd.read_csv(data_dir / \"NDC_product_table.csv\", encoding='ISO-8859-1')\n",
    "    df.NONPROPRIETARYNAME = df.NONPROPRIETARYNAME.fillna(\"\")\n",
    "    df.NONPROPRIETARYNAME = df.NONPROPRIETARYNAME.apply(str.lower)\n",
    "    df.PROPRIETARYNAME = df.PROPRIETARYNAME.fillna(\"\")\n",
    "    df.PROPRIETARYNAME = df.PROPRIETARYNAME.apply(str.lower)\n",
    "    return df\n",
    "ndc_drug_synonyms = read_drugs()\n",
    "ndc_drug_synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectdd.drug_index import DrugIndex\n",
    "\n",
    "drug_index = DrugIndex.init_with_drugbank()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_hosp_drugs():\n",
    "    sql_hosp_drugs_query = \"\"\"\n",
    "    SELECT \"\"\"\n",
    "    BigQueryClient.auth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_match():\n",
    "    df = (icu_drugs.merge(\n",
    "        ndc_drug_synonyms.drop_duplicates(subset=\"NONPROPRIETARYNAME\"), left_on= ['label'], right_on=['NONPROPRIETARYNAME'], how='left', indicator=True)[['itemid', 'label', 'category', 'PRODUCTID', 'NONPROPRIETARYNAME', ]]\n",
    "          .merge(ndc_drug_synonyms.drop_duplicates(subset=\"PROPRIETARYNAME\"), left_on=['label'], right_on='PROPRIETARYNAME', how='left', indicator=True))\n",
    "    print(df.count())\n",
    "    return df\n",
    "\n",
    "matched = exact_match()\n",
    "matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched.loc[matched._merge != 'both']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fuzzy_match(str1, str2):\n",
    "    return fuzz.token_set_ratio(str1, str2)\n",
    "\n",
    "def match_dataframe(df1, key1, df2, key2, threshold=90):\n",
    "    matches = []\n",
    "    # matches = pd.DataFrame(columns=['index', 'label', 'norm_label', 'match0', 'match1'])\n",
    "    for i, row in df1.iterrows():\n",
    "        drug_name = row[key1]\n",
    "        fast = True\n",
    "        to_match = df2[key2]\n",
    "        if fast:\n",
    "            to_match = to_match.loc[to_match.str.startswith(drug_name[0])] # speed up fuzzy matching by only considering synonyms that start with the same letter\n",
    "\n",
    "        match = process.extractOne(drug_name, to_match, scorer=fuzzy_match)\n",
    "        print(match)\n",
    "        matched_label = match[0]\n",
    "        match_score = match[1]\n",
    "        match_index = match[2]\n",
    "        if match_score >= threshold:\n",
    "            raw_match = df2.loc[match_index]\n",
    "            norm_label = raw_match.NONPROPRIETARYNAME\n",
    "            print(f\"Found match with score ({str(match[1])}) : {row[key1]} - {matched_label} -- norm label {norm_label}\")\n",
    "            matches.append([i, row['itemid'],row[key1], norm_label, matched_label, match_score, match_index])\n",
    "        print(i)\n",
    "\n",
    "    return pd.DataFrame(matches, columns=['index', 'itemid', 'label', 'norm_label', 'matched_label', 'score', 'norm_index'])\n",
    "\n",
    "\n",
    "\n",
    "def fuzzy_merge():\n",
    "    medications = icu_drugs.loc[(~icu_drugs['category'].isin(['Medications']))]\n",
    "\n",
    "    proprietary = match_dataframe(medications, \"label\", ndc_drug_synonyms, \"PROPRIETARYNAME\")\n",
    "    return proprietary\n",
    "\n",
    "fuzzy_matched = fuzzy_merge()\n",
    "fuzzy_matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = ndc_drug_synonyms['PROPRIETARYNAME'].str.startswith(\"glyc\")\n",
    "ndc_drug_synonyms.loc[m1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = ~matched['PRODUCTID_x'].isnull()\n",
    "m2 = ~matched['PRODUCTID_y'].isnull()\n",
    "has_product_id = m1 | m2\n",
    "matched.loc[~has_product_id].groupby('category').count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched.loc[(~matched['category'].isin(['Medications'])) & has_product_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icu_drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ddinter():\n",
    "    ddinter_files = os.listdir(ddinter_data_dir)\n",
    "\n",
    "    # loop through ddinter files\n",
    "    df = pd.DataFrame()\n",
    "    for file_name in ddinter_files:\n",
    "        df = pd.concat([df, pd.read_csv(ddinter_data_dir / file_name)])\n",
    "\n",
    "    df.Drug_B = df.Drug_B.fillna(\"\")\n",
    "    df.Drug_B = df.Drug_B.apply(str.lower)\n",
    "    df.Drug_B = df.Drug_B.fillna(\"\")\n",
    "    df.Drug_B = df.Drug_B.apply(str.lower)\n",
    "\n",
    "    df.Drug_A = df.Drug_A.fillna(\"\")\n",
    "    df.Drug_A = df.Drug_A.apply(str.lower)\n",
    "    df.Drug_A = df.Drug_A.fillna(\"\")\n",
    "    df.Drug_A = df.Drug_A.apply(str.lower)\n",
    "    return df\n",
    "\n",
    "ddinter = read_ddinter()\n",
    "cleaned= ddinter.loc[ddinter.Level.isin( ['Major'])]\n",
    "# cleaned = cleaned.loc[(cleaned['Drug_B'].isin( fuzzy_matched['norm_label_x']) | cleaned['Drug_A'].isin( fuzzy_matched['norm_label_x']))]\n",
    "cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interaction_clause_with_synonyms():\n",
    "    multimap = cleaned.groupby('Drug_A')['Drug_B'].apply(list).to_dict()\n",
    "    clauses= []\n",
    "    for key in multimap.keys():\n",
    "        first_ids = fuzzy_matched.loc[(fuzzy_matched['norm_label'] == key)]['itemid']\n",
    "\n",
    "        second_ids = fuzzy_matched.loc[(fuzzy_matched['norm_label'].isin(multimap[key]))]['itemid']\n",
    "        if first_ids.any() & second_ids.any():\n",
    "            sql = f\"(first_ie.itemid IN ({','.join([str(item) for item in first_ids if item])}) AND second_ie.itemid IN ({','.join([str(item) for item in second_ids if item])}))\"\n",
    "            clauses.append(sql)\n",
    "    print(len(clauses))\n",
    "    clause = \" OR \".join(clauses)\n",
    "    print (clause)\n",
    "    return clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interaction_clause_raw():\n",
    "    multimap = cleaned.groupby('Drug_A')['Drug_B'].apply(list).to_dict()\n",
    "    print(len(multimap))\n",
    "    clauses= []\n",
    "    for key in multimap.keys():\n",
    "        first_ids = icu_drugs.loc[(icu_drugs['label'] == key)]['itemid']\n",
    "        \n",
    "        second_ids = icu_drugs.loc[(icu_drugs['label'].isin(multimap[key]))]['itemid']\n",
    "        if first_ids.any() & second_ids.any():\n",
    "            sql = f\"\\n(first_ie.itemid IN ({','.join([str(item) for item in first_ids if item])}) AND second_ie.itemid IN ({','.join([str(item) for item in second_ids if item])}))\"\n",
    "            clauses.append(sql)\n",
    "    clause = \" OR \".join(clauses)\n",
    "    return clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multimap = cleaned.groupby('Drug_A')['Drug_B'].apply(list).to_dict()\n",
    "def query_for_drug_interactions(type='synonyms'):\n",
    "    \n",
    "    if type == 'synonyms':\n",
    "        clause = get_interaction_clause_with_synonyms()\n",
    "    else:\n",
    "        clause = get_interaction_clause_raw()\n",
    "    icu = \"physionet-data.mimiciv_icu\"\n",
    "\n",
    "    sql = f\"\"\"SELECT first_ie.subject_id, first_ie.hadm_id, first_ie.stay_id, first_ie.itemid as drug_a_item_id, second_ie.itemid as drug_b_item_id, MAX(second_ie.starttime) as dose_b_time, count(*) as event_count\n",
    "        FROM `{icu}.inputevents` as first_ie\n",
    "        INNER JOIN `{icu}.inputevents` as second_ie ON first_ie.stay_id = second_ie.stay_id\n",
    "        WHERE {clause} AND first_ie.amount > 0\n",
    "            AND second_ie.amount > 0\n",
    "            AND first_ie.starttime < second_ie.starttime\n",
    "            AND DATETIME_DIFF(second_ie.starttime, first_ie.starttime, MINUTE) < 300\n",
    "        GROUP BY first_ie.subject_id, first_ie.hadm_id, first_ie.stay_id, first_ie.itemid, second_ie.itemid, second_ie.starttime\n",
    "    \"\"\"\n",
    "    print(\"\\n\\n\",sql)\n",
    "    mimic_job = BigQueryClient.auth().query(sql)\n",
    "    return mimic_job.to_dataframe()\n",
    "\n",
    "drug_interactions_raw = query_for_drug_interactions(type='raw')\n",
    "drug_interactions_synonyms = query_for_drug_interactions()\n",
    "drug_interactions = pd.concat([drug_interactions_synonyms, drug_interactions_raw]).drop_duplicates()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectdd.serializer import Serializer\n",
    "\n",
    "serializer = Serializer()\n",
    "serializer.write_cohort(drug_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serializer.read_cohort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(drug_interactions.event_count.sum())\n",
    "\n",
    "drug_interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_interactions.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_interactions.loc[drug_interactions.event_count < 18].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
