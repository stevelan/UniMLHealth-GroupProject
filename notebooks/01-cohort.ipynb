{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectdd import config\n",
    "from detectdd.serializer import Serializer\n",
    "import root_config as rc #this is needed to resolve the local modules\n",
    "rc.configure()\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "from detectdd.config import *\n",
    "from detectdd.auth_bigquery import BigQueryClient\n",
    "\n",
    "if config.isFastMode():\n",
    "    print(\"running in FAST mode\")\n",
    "else:\n",
    "    print(\"Running in FULL mode\")\n",
    "    \n",
    "serializer = Serializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    mimic_drugs = f\"\"\"\n",
    "        SELECT itemid, label, abbreviation, category, unitname\n",
    "        FROM {icu_d_items}\n",
    "        WHERE linksto='inputevents' \"\"\"\n",
    "\n",
    "    mimic_job = BigQueryClient.auth().query(mimic_drugs)\n",
    "    df = mimic_job.to_dataframe()\n",
    "    df.label = df.label.fillna(\"\")\n",
    "    df.label = df.label.apply(str.lower)\n",
    "    return df\n",
    "\n",
    "icu_drugs = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectdd.drug_index import DrugIndex, index_mimic_drugs, clean\n",
    "\n",
    "drug_index = DrugIndex.get_drug_index()\n",
    "\n",
    "drug_index.drug_bank_df['cleaned'] = drug_index.drug_bank_df['Common name'].apply(clean)\n",
    "drug_index.drug_bank_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectdd.drug_index import clean\n",
    "\n",
    "def read_hosp_drugs():\n",
    "    sql_hosp_drugs_query = f\"\"\"\n",
    "    SELECT distinct medication from {config.hosp}.emar\"\"\"\n",
    "    return BigQueryClient.auth().query(sql_hosp_drugs_query).to_dataframe()\n",
    "\n",
    "df_hosp_drugs = read_hosp_drugs()['medication'].astype(str)\n",
    "\n",
    "df_hosp_drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df_hosp_drugs)\n",
    "drugs_by_norm_name = index_mimic_drugs(pd.DataFrame(df_hosp_drugs), \"medication\", \"medication\")\n",
    "drugs= pd.DataFrame.from_dict(drugs_by_norm_name, orient=\"index\")\n",
    "drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fuzzy_match(str1, str2):\n",
    "    return fuzz.token_set_ratio(str1, str2)\n",
    "\n",
    "def match_dataframe(df1, key1, df2, key2, threshold=88): #threshold from inspection of data\n",
    "    matches = []\n",
    "    # matches = pd.DataFrame(columns=['index', 'label', 'norm_label', 'match0', 'match1'])\n",
    "    for i, row in df1.iterrows():\n",
    "        drug_name = row[key1]\n",
    "        fast = True\n",
    "        to_match = df2[key2]\n",
    "        if config.isFastMode():\n",
    "            to_match = to_match.loc[to_match.str.startswith(drug_name[0])] # speed up fuzzy matching by only considering synonyms that start with the same letter\n",
    "\n",
    "        match = process.extractOne(drug_name, to_match, scorer=fuzzy_match)\n",
    "        print(match)\n",
    "        matched_label = match[0]\n",
    "        match_score = match[1]\n",
    "        match_index = match[2]\n",
    "        if match_score >= threshold:\n",
    "            raw_match = df2.loc[match_index]\n",
    "            norm_label = raw_match[key2]\n",
    "            print(f\"Found match with score ({str(match[1])}) : {row[key1]} - {matched_label} -- norm label {norm_label}\")\n",
    "            matches.append([i, row['itemid'],row[key1], norm_label, matched_label, match_score, match_index])\n",
    "        print(i)\n",
    "\n",
    "    return pd.DataFrame(matches, columns=['index', 'itemid', 'label', 'norm_label', 'matched_label', 'score', 'norm_index'])\n",
    "\n",
    "\n",
    "\n",
    "def fuzzy_merge():\n",
    "    medications = icu_drugs.loc[(~icu_drugs['category'].isin(['Medications']))]\n",
    "\n",
    "    proprietary = match_dataframe(medications, \"label\", drug_index.drug_bank_df, \"cleaned\")\n",
    "    return proprietary\n",
    "\n",
    "fuzzy_matched = fuzzy_merge()\n",
    "fuzzy_matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fuzzy_matched\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icu_drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ddinter():\n",
    "    ddinter_files = os.listdir(ddinter_data_dir)\n",
    "\n",
    "    # loop through ddinter files\n",
    "    df = pd.DataFrame()\n",
    "    for file_name in ddinter_files:\n",
    "        df = pd.concat([df, pd.read_csv(ddinter_data_dir / file_name)])\n",
    "\n",
    "    df.Drug_B = df.Drug_B.fillna(\"\")\n",
    "    df.Drug_B = df.Drug_B.apply(clean)\n",
    "\n",
    "    df.Drug_A = df.Drug_A.fillna(\"\")\n",
    "    df.Drug_A = df.Drug_A.apply(clean)\n",
    "    return df\n",
    "\n",
    "ddinter = read_ddinter()\n",
    "cleaned= ddinter.loc[ddinter.Level.isin( ['Major'])]\n",
    "cleaned = cleaned.drop_duplicates()\n",
    "cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ddinter_multimap():\n",
    "    multimap = cleaned.groupby('Drug_A')['Drug_B'].apply(set).to_dict()\n",
    "    opp_direction = cleaned.groupby('Drug_B')['Drug_A'].apply(set).to_dict()\n",
    "    for key in opp_direction.keys():\n",
    "        existing = multimap.get(key)\n",
    "        if existing is None:\n",
    "            existing = set()\n",
    "        existing |= opp_direction[key]\n",
    "        multimap[key] = existing\n",
    "    return multimap\n",
    "    \n",
    "    multimap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interaction_clause_with_synonyms():\n",
    "    multimap = get_ddinter_multimap()\n",
    "    \n",
    "    clauses= []\n",
    "    for key in multimap.keys():\n",
    "        first_ids = fuzzy_matched.loc[(fuzzy_matched['norm_label'] == key)]['itemid']\n",
    "\n",
    "        second_ids = fuzzy_matched.loc[(fuzzy_matched['norm_label'].isin(multimap[key]))]['itemid']\n",
    "        if first_ids.any() & second_ids.any():\n",
    "            sql = f\"(first_ie.itemid IN ({','.join([str(item) for item in first_ids if item])}) AND second_ie.itemid IN ({','.join([str(item) for item in second_ids if item])}))\"\n",
    "            clauses.append(sql)\n",
    "    print(len(clauses))\n",
    "    clause = \" OR \".join(clauses)\n",
    "    print (clause)\n",
    "    print(f\"Found {len(clauses)} first ids\")\n",
    "    return clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interaction_clause_raw():\n",
    "    multimap = get_ddinter_multimap()\n",
    "    print(len(multimap))\n",
    "    clauses= []\n",
    "    first_match_count = 0\n",
    "    for key in multimap.keys():\n",
    "        first_ids = icu_drugs.loc[(icu_drugs['label'] == key)]['itemid']\n",
    "        if first_ids.any():\n",
    "            first_match_count += 1\n",
    "        \n",
    "        second_ids = icu_drugs.loc[(icu_drugs['label'].isin(multimap[key]))]['itemid']\n",
    "        if first_ids.any() & second_ids.any():\n",
    "            sql = f\"\\n(first_ie.itemid IN ({','.join([str(item) for item in first_ids if item])}) AND second_ie.itemid IN ({','.join([str(item) for item in second_ids if item])}))\"\n",
    "            clauses.append(sql)\n",
    "    clause = \" OR \".join(clauses)\n",
    "    print(f\"Found {first_match_count} administered ddinter keys\")\n",
    "    print(f\"Found {len(clauses)} clauses\")\n",
    "    return clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multimap = get_ddinter_multimap()\n",
    "df = pd.DataFrame()\n",
    "df['dinter'] = pd.Series(multimap.keys()).sort_values()\n",
    "val = list(icu_drugs['label'])\n",
    "val.sort()\n",
    "df['icu_labels'] = pd.Series(val)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"Found {len(df.loc[df['dinter'].isin(drug_index.indexed_synonyms)])} ddinter keys in drugbank of {len(df['dinter'])}\")\n",
    "\n",
    "medication = pd.DataFrame()\n",
    "medication['medication'] = icu_drugs['label']\n",
    "\n",
    "def compare_to_ddinter(to_compare, descriptor):\n",
    "    print(f\"\\nTotal {len(to_compare)} {descriptor} drugs\")\n",
    "    print(f\"Found {len(to_compare.loc[to_compare['medication'].isin(df['dinter'])])} {descriptor} drugs in dinter without using synonyms\")\n",
    "    to_compare = to_compare.loc[~to_compare['medication'].isin(df['dinter'])]['medication']\n",
    "    print(f\"Found {len(to_compare.loc[to_compare.isin(drug_index.common_names)])} icu drugs in indexed common names\")\n",
    "    to_compare = to_compare.loc[~to_compare.isin(drug_index.common_names)]\n",
    "    print(f\"Found {len(to_compare.loc[to_compare.isin(drug_index.indexed_synonyms)])} icu drugs in indexed synonyms\")\n",
    "\n",
    "compare_to_ddinter(medication, 'icu')\n",
    "medication = pd.DataFrame()\n",
    "medication['medication'] = df_hosp_drugs\n",
    "compare_to_ddinter(medication, 'hosp')\n",
    "\n",
    "print(f\"Found {len(df_hosp_drugs[~df_hosp_drugs.isin(icu_drugs['label'])])} hosp drugs not in icu_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_for_drug_interactions(type='synonyms'):\n",
    "   \n",
    "    if type == 'synonyms':\n",
    "        clause = get_interaction_clause_with_synonyms()\n",
    "    else:\n",
    "        clause = get_interaction_clause_raw()\n",
    "    icu = \"physionet-data.mimiciv_icu\"\n",
    "\n",
    "    sql = f\"\"\"SELECT first_ie.subject_id, first_ie.hadm_id, first_ie.stay_id, first_ie.itemid as drug_a_item_id, second_ie.itemid as drug_b_item_id, MAX(second_ie.starttime) as dose_b_time, count(*) as event_count\n",
    "        FROM `{icu}.inputevents` as first_ie\n",
    "        INNER JOIN `{icu}.inputevents` as second_ie ON first_ie.stay_id = second_ie.stay_id\n",
    "        WHERE {clause} AND first_ie.amount > 0\n",
    "            AND second_ie.amount > 0\n",
    "            AND first_ie.starttime < second_ie.starttime\n",
    "            AND DATETIME_DIFF(second_ie.starttime, first_ie.starttime, MINUTE) < 300\n",
    "        GROUP BY first_ie.subject_id, first_ie.hadm_id, first_ie.stay_id, first_ie.itemid, second_ie.itemid, second_ie.starttime\n",
    "    \"\"\"\n",
    "    print(\"\\n\\n\",sql)\n",
    "    mimic_job = BigQueryClient.auth().query(sql)\n",
    "    return mimic_job.to_dataframe()\n",
    "\n",
    "interaction_clause = 'synonyms'\n",
    "if config.isFastMode():\n",
    "    interaction_clause = 'raw'\n",
    "\n",
    "interaction_clause = 'raw'\n",
    "icu_drug_interactions_raw = query_for_drug_interactions(type='raw')\n",
    "icu_drug_interactions_synonyms = query_for_drug_interactions(type='synonyms')\n",
    "print(f\"raw interactions {len(icu_drug_interactions_raw)}\")\n",
    "print(f\"synonym interactions {len(icu_drug_interactions_synonyms)}\")\n",
    "icu_drug_interactions = pd.concat([icu_drug_interactions_synonyms, icu_drug_interactions_raw]).drop_duplicates()\n",
    "print(f\"combined interactions {len(icu_drug_interactions)}\")\n",
    "print(f\"Total unique hadms: {len(icu_drug_interactions.drop_duplicates()['hadm_id'].drop_duplicates())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "icu_drug_interactions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icu_drug_interactions.drop_duplicates()['hadm_id'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emar_interaction_clause():\n",
    "    multimap = get_ddinter_multimap()\n",
    "    clauses= []\n",
    "    for key in multimap.keys():\n",
    "        first_id = drugs_by_norm_name.get(key).db_identifier if drugs_by_norm_name.get(key) is not None else None\n",
    "        # first_ids = drugs_by_norm_name.get[(drugs_by_norm_name['common_name'] == key)]['db_identifier']\n",
    "\n",
    "        second_ids = []\n",
    "        for inter_key in multimap[key]:\n",
    "            if drugs_by_norm_name.get(inter_key):\n",
    "                second_ids.append(drugs_by_norm_name[inter_key].db_identifier)\n",
    "        \n",
    "        if bool(first_id) & len(second_ids) > 0:\n",
    "            inclause = \"','\".join([str(item) for item in second_ids if item])\n",
    "            sql = f\"(e1.medication = '{first_id}' AND e2.medication IN ('{inclause}'))\\n\"\n",
    "            clauses.append(sql)\n",
    "    print(f\"Found {len(clauses)} hosp interactions\")\n",
    "    return clauses\n",
    "\n",
    "get_emar_interaction_clause()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emar table has more drugs administered than the icu records\n",
    "def query_for_emar_drug_interactions():\n",
    "    # clauses = [\"e1.medication = 'Citalopram' AND e2.medication IN ('Insulin')\", \"e1.medication = 'Insulin' AND e2.medication IN ('Citalopram')\"]\n",
    "    clauses = get_emar_interaction_clause()\n",
    "    event_txt_not_status = ('Not Given', 'Not Started', 'Not Confirmed')\n",
    "    sql = f\"\"\"\n",
    "        SELECT e1.subject_id, e1.hadm_id, \n",
    "        e1.medication as medication_1, \n",
    "        e2.medication as medication_2,\n",
    "        e1.charttime as charttime_1 ,\n",
    "        e2.charttime as charttime_2,\n",
    "        e1.event_txt,\n",
    "        e2.event_txt, \n",
    "        stays.stay_id, \n",
    "        stays.intime\n",
    "        FROM `physionet-data.mimiciv_hosp.emar` as e1\n",
    "        INNER JOIN `physionet-data.mimiciv_hosp.emar` as e2\n",
    "            ON e1.hadm_id = e2.hadm_id \n",
    "                AND e2.charttime > e1.charttime\n",
    "                AND DATETIME_DIFF(e2.charttime, e1.charttime, MINUTE) < 720\n",
    "        INNER JOIN `physionet-data.mimiciv_icu.icustays` as stays ON e1.subject_id = stays.subject_id\n",
    "            AND (stays.intime > e2.charttime AND DATETIME_DIFF(stays.intime, e2.charttime, HOUR) < 24 OR (e2.charttime BETWEEN stays.intime AND stays.outtime))\n",
    "        WHERE\n",
    "            e1.event_txt NOT IN {event_txt_not_status}\n",
    "            AND e2.event_txt NOT IN {event_txt_not_status}\n",
    "            AND \n",
    "            (\n",
    "                {' OR '.join(clauses)}\n",
    "            )\n",
    "    \"\"\"\n",
    "    print(sql)\n",
    "    return BigQueryClient.auth().query(sql).to_dataframe()\n",
    "    \n",
    "hosp_drug_interactions = query_for_emar_drug_interactions()    \n",
    "print(f\"Found {len(hosp_drug_interactions)} emar drug events\")\n",
    "\n",
    "hosp_drug_interactions = hosp_drug_interactions.drop_duplicates()\n",
    "hosp_drug_interactions['hadm_id'].drop_duplicates()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "icu_drug_interactions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# merge icu and emar drug interactions\n",
    "\n",
    "mergeable_hosp_interactions = pd.DataFrame(hosp_drug_interactions[['subject_id', 'hadm_id', 'stay_id']])\n",
    "mergeable_hosp_interactions['drug_a_item_id'] = hosp_drug_interactions.medication_1\n",
    "mergeable_hosp_interactions['drug_b_item_id'] = hosp_drug_interactions.medication_2\n",
    "mergeable_hosp_interactions['dose_b_time'] = hosp_drug_interactions.charttime_2\n",
    "mergeable_hosp_interactions['event_count'] = 0 # dummy value\n",
    "\n",
    "combined_drug_interactions = pd.concat([icu_drug_interactions, mergeable_hosp_interactions])\n",
    "combined_drug_interactions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from detectdd.serializer import Serializer \n",
    "serializer = Serializer()\n",
    "serializer.write_total_drug_interactions(combined_drug_interactions)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serializer.write_icu_drug_interactions(icu_drug_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "serializer.write_emar_drug_interactions(hosp_drug_interactions.drop_duplicates())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serializer.read_total_drug_interactions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(icu_drug_interactions.event_count.sum())\n",
    "\n",
    "icu_drug_interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "icu_drug_interactions.event_count.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# remove outliers, q75 + 1.5 x IQR = 11 + 1.5 * 6 =  18\n",
    "# filter for events with count below \n",
    "drug_interactions_truncated = icu_drug_interactions.loc[icu_drug_interactions.event_count < 18]\n",
    "print(len(drug_interactions_truncated))\n",
    "plt = drug_interactions_truncated.boxplot(column=\"event_count\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
