{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from detectdd import config\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras\n",
    "# import tensorflow.keras\n",
    "\n",
    "import root_config as rc\n",
    "import pandas as pd\n",
    "from detectdd.serializer import Serializer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rc.configure()\n",
    "\n",
    "\n",
    "bp_df = pd.read_csv(config.out_dir /'vitals_data-10.csv')\n",
    "print(bp_df.dtypes)\n",
    "\n",
    "bp_df[\"charttime\"] = bp_df[\"charttime\"].astype(\"datetime64[s]\")\n",
    "bp_df[\"dose_b_time\"] = bp_df[\"dose_b_time\"].astype(\"datetime64[s]\")\n",
    "\n",
    "bp_df = bp_df.sort_values(by=[\"stay_id\", \"dose_b_time\", \"charttime\"])\n",
    "\n",
    "bp_df[\"has_icd\"] = 1\n",
    "bp_df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "71bb824da43eebaa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bp_df_no_icd = serializer.read_bp_results(\"10-no-icd\")\n",
    "bp_df_no_icd[\"has_icd\"] = 0\n",
    "bp_df_no_icd\n",
    "df = bp_df\n",
    "# df= pd.concat([bp_df, bp_df_no_icd])\n",
    "df.head(50)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30869887ad752c36"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"charttime\"] = df[\"charttime\"].astype(\"datetime64[s]\")\n",
    "df[\"dose_b_time\"] = df[\"dose_b_time\"].astype(\"datetime64[s]\")\n",
    "\n",
    "df.dtypes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f74b3246f2c2e4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "## convert chart_time to timestep relative to dose b time\n",
    "df[\"timestep\"] = df[\"charttime\"] - df[\"dose_b_time\"] \n",
    "## and convert to float64 for tensor flow\n",
    "df['timestep_float'] = df['timestep'].dt.total_seconds().astype('float64')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bbdedf0ecd5747bd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df[[\"stay_id\", \"timestep\", \"timestep_float\", \"heart_rate\", \"sbp\", \"dbp\", \"mbp\", \"dose_b_time\", \"charttime\", \"has_icd\"]].sort_values([\"stay_id\", \"dose_b_time\", \"timestep\"])\n",
    "df.head(50)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9425cee888566589"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a849a0e0ee1357b9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "group_df = df[[\"stay_id\", \"dose_b_time\", \"timestep_float\", \"heart_rate\", \"sbp\", \"dbp\", \"mbp\", \"has_icd\"]]\n",
    "grouped_df = group_df.groupby([\"stay_id\", \"has_icd\", \"dose_b_time\"]).agg(lambda x: list(x)).reset_index()\n",
    "\n",
    "print(grouped_df)\n",
    "print(grouped_df.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "973f50807e404908"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final_bp = grouped_df\n",
    "\n",
    "# reduce the size of the data arrays to the p999 to get rid of the extreme outliers\n",
    "length = pd.DataFrame()\n",
    "length[\"val\"] = [len(array) for array in final_bp[\"mbp\"]]\n",
    "print(length.describe(percentiles=[0.01, 0.025, 0.25, 0.5, 0.75, 0.975, 0.99, 0.999]))\n",
    "\n",
    "\n",
    "max_size = 98 # p999\n",
    "\n",
    "data_arrays = [\"timestep_float\", \"heart_rate\", \"sbp\", \"dbp\", \"mbp\"]\n",
    "for data_array in data_arrays:\n",
    "    final_bp[data_array] = final_bp[data_array].apply(lambda arr: arr[:max_size]) # shrink it\n",
    "\n",
    "max_sequence_length = max(len(array) for array in final_bp[\"sbp\"])\n",
    "final_bp = final_bp"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7577b32922b217c7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# first fill blank values through interpellation\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def interpolate_row(row):\n",
    "    \n",
    "    time_steps = np.array(row[\"timestep_float\"])\n",
    "    common_time_interval = range(0, 12*60, 10)\n",
    "    \n",
    "    for data_array in [\"sbp\", \"mbp\", \"dbp\", \"heart_rate\"]:\n",
    "\n",
    "        # # convert to arrays for interpolation\n",
    "        # row[data_array] = np.array(row[data_array])\n",
    "        # \n",
    "        # nan_indices = np.isnan(row[data_array])\n",
    "        # if np.count_nonzero(nan_indices) > 1:\n",
    "        #     missing_values =  interp1d(time_steps[~nan_indices], row[data_array][~nan_indices] , kind='linear', fill_value='extrapolate')\n",
    "        #     row[data_array] = missing_values(time_steps)\n",
    "        \n",
    "        interp_func = interp1d(time_steps, row[data_array], kind='nearest-up', fill_value='extrapolate')\n",
    "        row[\"intr-\"+data_array] = interp_func(common_time_interval)\n",
    "    \n",
    "    row[\"common_timestep\"] = common_time_interval\n",
    "    return row\n",
    "\n",
    "# Apply the function to the specific subset of rows\n",
    "final_bp = final_bp.apply(interpolate_row, axis=1)\n",
    "final_bp.head(50)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bf9396b30fdfa6e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "print(len(final_bp.loc[0].timestep_float))\n",
    "print(len(final_bp.loc[0][\"heart_rate\"]))\n",
    "print(len(final_bp.loc[0][\"intr-heart_rate\"]))\n",
    "print(len(final_bp.loc[0][\"common_timestep\"]))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "637472fd5703a23e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from numpy import shape\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "target = 'has_icd'\n",
    "\n",
    "# Extract features and timestep data\n",
    "features = ['heart_rate', 'sbp', 'dbp', 'mbp']\n",
    "timesteps = final_bp['common_timestep'].tolist()\n",
    "\n",
    "# Determine the maximum sequence length\n",
    "max_sequence_length = max(len(seq) for seq in timesteps)\n",
    "print(max_sequence_length)\n",
    "print(max_sequence_length)\n",
    "\n",
    "print(max(len(dosages) for dosages in final_bp.groupby('stay_id')))\n",
    "\n",
    "# Organize data by stay_id\n",
    "stay_ids = final_bp['stay_id'].unique()\n",
    "X_sequences = []\n",
    "y_sequences = []\n",
    "\n",
    "for stay_id in stay_ids:\n",
    "    stay_data = final_bp[final_bp['stay_id'] == stay_id]\n",
    "    stay_X = []\n",
    "    for index, row in stay_data.iterrows():\n",
    "        dose_features = row[features].to_numpy()\n",
    "    \n",
    "        # Pad or truncate sequences to the maximum length\n",
    "        dose_features_padded = pad_sequences(dose_features_padded, maxlen=max_sequence_length, dtype='float32', padding='post', truncating='post')\n",
    "        stay_X.append(dose_features_padded)\n",
    "    \n",
    "    X_sequences.append(stay_X)\n",
    "    # Extract targets for each stay_id \n",
    "    labels = stay_data[target].tolist() \n",
    "    y_sequences.append(labels[0])\n",
    "\n",
    "\n",
    "X = X_sequences\n",
    "y = y_sequences\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "1a076c674ca138cc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(X))\n",
    "print(len(y))\n",
    "\n",
    "#Adjust the size of the testing set: we'll use 10% of the entire data. \n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size = 0.1, random_state = 1)\n",
    "\n",
    "#Check the number of columns (features):\n",
    "print(len(X_train))\n",
    "print(type(X))\n",
    "print(type(y))\n",
    "y"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba5b915cab2f0376"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(max_sequence_length)\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "max_feature_dim = 4\n",
    "\n",
    "model.add(keras.layers.Masking(mask_value=0, input_shape=(max_sequence_length, None, max_feature_dim)))\n",
    "model.add(keras.layers.Reshape((-1, 5)))\n",
    "model.add(keras.layers.LSTM(64))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c1ca833717a939a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24fd5efbe0bd6613"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ragged_tensors = []\n",
    "\n",
    "final_bp['dose_num'] = df.groupby('stay_id').cumcount() + 1\n",
    "\n",
    "for _, group in final_bp[['stay_id', 'dose_num', 'intr-heart_rate', \"intr-sbp\", \"intr-mbp\", \"intr-dbp\", 'common_timestep']].groupby('stay_id'):\n",
    "\n",
    "    feature_data_list = group[['intr-heart_rate', \"intr-sbp\", \"intr-mbp\", \"intr-dbp\", 'common_timestep']].values.tolist()\n",
    "\n",
    "    feature_data_ragged = tf.ragged.constant(feature_data_list, dtype=tf.float32)\n",
    "    ragged_tensors.append(feature_data_ragged)\n",
    "\n",
    "# Convert the list of RaggedTensor objects into a 3D RaggedTensor\n",
    "sequences_ragged = tf.ragged.stack(ragged_tensors, axis=0)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61d79c8da7c51e0a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Convert the organized data into tensors\n",
    "# X_tensor = tf.convert_to_tensor(X_train, dtype='float32')\n",
    "y_tensor = tf.ragged.constant(y_sequences, dtype='float32')\n",
    "\n",
    "simple = tf.constant(y, dtype='float32')\n",
    "\n",
    "classifier = model.fit(sequences_ragged, simple, epochs=50, batch_size=100, verbose=1) #set verbose = 1 to see the fitting process"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4263eb1674d3a26c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot Accuracy over the epochs\n",
    "plt.plot(classifier.history['accuracy'])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.title('model accuracy')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot Loss over the epochs\n",
    "plt.plot(classifier.history['loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.title('model loss')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd261ac8e14dba93"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "type(X_train)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60fd74d96e88415c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60c0968f2cea6306"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "88743f97d504f1ce"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
