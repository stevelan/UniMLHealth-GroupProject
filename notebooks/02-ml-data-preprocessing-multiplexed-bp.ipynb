{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### This is a copu of ml-data-preprocessing, written to help with scaffolding for the query multiplexer.\n",
    "### 02-ml-data-preprocessing is still the main preprocessing file\n",
    "\n",
    "### ML Data pre-processing\n",
    "This notebook is for loading and cleaning the data that will be used to train the ML on.\n",
    "Things like patient heart rate and blood pressure readings that occurred around the time of the administration of the second dose \n",
    "\n",
    "It should persist the data into the \"out\" directory to be consumed by the ml training notebook"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f8191d46f8661e5"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cohort\n",
      "Loaded cohort from ..\\out\\cohort-full.out\n",
      "<google.oauth2.credentials.Credentials object at 0x000002A37B04E740> mimic-iv-desktop\n",
      "1544\n"
     ]
    }
   ],
   "source": [
    "import root_config as rc\n",
    "from detectdd import config\n",
    "import pandas as pd\n",
    "\n",
    "rc.configure()\n",
    "\n",
    "from detectdd.auth_bigquery import BigQueryClient\n",
    "from detectdd.serializer import Serializer\n",
    "\n",
    "print(\"Loading cohort\")\n",
    "\n",
    "try:\n",
    "    serializer = Serializer()\n",
    "    cohort_with_icd = serializer.read_cohort()  # need to run 01-cohort.ipynb to produce the cohort\n",
    "except FileNotFoundError:\n",
    "    raise Exception(\"Need to run [01-cohort.ipynb] at least once to create the cohort file in the /out directory\")\n",
    "\n",
    "big_query = BigQueryClient.auth()\n",
    "\n",
    "\n",
    "from detectdd.query_multiplexer import WhereClauseGenerator\n",
    "from detectdd.query_multiplexer import QueryMultiplexer\n",
    "import pandas as pd\n",
    "from detectdd.auth_bigquery import BigQueryClient\n",
    "\n",
    "cohort_with_no_ddi = pd.read_csv(config.out_dir / 'non-drug-interactions.csv')\n",
    "\n",
    "cohort_with_no_ddi[\"dose_b_time\"] = cohort_with_no_ddi[\"dose_b_time\"].astype(\"datetime64[s]\")\n",
    "\n",
    "cohort_with_no_ddi.nunique()\n",
    "\n",
    "# fetch this data set\n",
    "data_cohort=cohort_with_icd\n",
    "cohort_filename = \"vitals_data_before_and_after_ABC.csv\"\n",
    "\n",
    "print(cohort_with_icd['subject_id'].nunique())\n",
    "#data_cohort=cohort_with_no_ddi\n",
    "#cohort_filename = \"vitals_data_before_and_after_no_drug_interaction.csv\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T00:47:38.752355800Z",
     "start_time": "2023-11-03T00:47:37.581061700Z"
    }
   },
   "id": "46f01d003a2af2b6"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing query 1, with 1679 pairs at 2023-11-03 11:47:38.859173\n",
      "Partitioning key value pairs 1679\n",
      "Number of partitions 6 with partition_size 279.8333333333333\n",
      "Got result with 9007 values\n",
      "Got result with 9556 values\n",
      "Got result with 9552 values\n",
      "Got result with 9576 values\n",
      "Got result with 9315 values\n",
      "Got result with 9313 values\n",
      "Executing query 2, with 1172 pairs at 2023-11-03 11:49:26.221430\n",
      "Single partition\n",
      "Got result with 39033 values\n",
      "Executing query 3, with 871 pairs at 2023-11-03 11:51:47.050386\n",
      "Single partition\n",
      "Got result with 28939 values\n",
      "Executing query 4, with 674 pairs at 2023-11-03 11:52:45.558002\n",
      "Single partition\n",
      "Got result with 22923 values\n",
      "Executing query 5, with 534 pairs at 2023-11-03 11:53:29.751083\n",
      "Single partition\n",
      "Got result with 17280 values\n",
      "Executing query 6, with 442 pairs at 2023-11-03 11:54:24.752125\n",
      "Single partition\n",
      "Got result with 14576 values\n",
      "Executing query 7, with 363 pairs at 2023-11-03 11:55:06.351172\n",
      "Single partition\n",
      "Got result with 11792 values\n",
      "Executing query 8, with 309 pairs at 2023-11-03 11:55:37.178721\n",
      "Single partition\n",
      "Got result with 10336 values\n",
      "Executing query 9, with 248 pairs at 2023-11-03 11:55:57.547059\n",
      "Single partition\n",
      "Got result with 8083 values\n",
      "Executing query 10, with 201 pairs at 2023-11-03 11:56:16.191824\n",
      "Single partition\n",
      "Got result with 6440 values\n",
      "Executing query 11, with 167 pairs at 2023-11-03 11:56:29.625366\n",
      "Single partition\n",
      "Got result with 5423 values\n",
      "Executing query 12, with 136 pairs at 2023-11-03 11:56:40.638083\n",
      "Single partition\n",
      "Got result with 4307 values\n",
      "Executing query 13, with 104 pairs at 2023-11-03 11:56:49.784660\n",
      "Single partition\n",
      "Got result with 3201 values\n",
      "Executing query 14, with 81 pairs at 2023-11-03 11:56:56.816449\n",
      "Single partition\n",
      "Got result with 2597 values\n",
      "Executing query 15, with 62 pairs at 2023-11-03 11:57:02.588133\n",
      "Single partition\n",
      "Got result with 2059 values\n",
      "Executing query 16, with 37 pairs at 2023-11-03 11:57:08.769218\n",
      "Single partition\n",
      "Got result with 1168 values\n",
      "Executing query 17, with 24 pairs at 2023-11-03 11:57:12.208818\n",
      "Single partition\n",
      "Got result with 790 values\n",
      "Executing query 18, with 14 pairs at 2023-11-03 11:57:15.065315\n",
      "Single partition\n",
      "Got result with 524 values\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming you have a Serializer class that handles reading your saved cohort data\n",
    "serializer = Serializer()\n",
    "\n",
    "# Extract unique subject_ids from the cohort data\n",
    "subject_ids = data_cohort['subject_id'].unique()\n",
    "\n",
    "# Convert the list of subject_ids to a format suitable for SQL query\n",
    "subject_id_str = ', '.join([str(id) for id in subject_ids])\n",
    "# print(subject_id_str)\n",
    "# Now, let's proceed to fetch the vital signs for these subject_ids from MIMIC\n",
    "\n",
    "query_multiplexer = QueryMultiplexer(big_query)\n",
    "\n",
    "# Write a SQL query to fetch the required vitals where the subject_ids are in your cohort\n",
    "query = \"\"\"\n",
    "SELECT stay_id, subject_id, charttime, heart_rate, sbp, dbp, mbp\n",
    "FROM `physionet-data.mimiciv_derived.vitalsign`\n",
    "WHERE ($where) \n",
    "    AND (heart_rate IS NOT NULL OR sbp IS NOT NULL OR dbp IS NOT NULL OR mbp IS NOT NULL)\n",
    "\"\"\"\n",
    "\n",
    "# query = f\"\"\"\n",
    "# SELECT subject_id, heart_rate, sbp, dbp, mbp\n",
    "# FROM `physionet-data.mimiciv_derived.vitalsign`\n",
    "# WHERE subject_id IN ({subject_id_str}) limit 100\"\"\"\n",
    "\n",
    "where_fragment = \"(stay_id= $stay_id AND charttime > DATETIME_ADD('$dose_b_time', INTERVAL -720 MINUTE) AND charttime < DATETIME_ADD('$dose_b_time', INTERVAL 720 MINUTE))\"\n",
    "\n",
    "multimap_data = {k: v.tolist() for k, v in data_cohort.groupby('stay_id')['dose_b_time']}\n",
    "results = query_multiplexer.multiplex_query(query, multi_map_data=multimap_data,\n",
    "                                            where_clause=WhereClauseGenerator(where_fragment, \"stay_id\", \"dose_b_time\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T00:57:17.963519600Z",
     "start_time": "2023-11-03T00:47:38.759337600Z"
    }
   },
   "id": "d647680bc5e6edd4"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "                         dose_b_time       subject_id  \\\ncount                         235790         235790.0   \nmean   2154-03-01 20:05:48.659060736  14942333.980826   \nmin              2110-03-02 18:20:00       10004733.0   \n25%              2133-10-25 16:44:00       12429062.0   \n50%              2154-01-19 13:42:00       14918516.0   \n75%              2175-10-03 12:42:00       17509107.0   \nmax              2209-05-30 02:04:00       19983257.0   \nstd                              NaN   2886914.165744   \n\n                        charttime     heart_rate            sbp  \\\ncount                      235790  181098.000000  184156.000000   \nmean   2154-03-01 20:06:03.497349      90.212652     116.615189   \nmin           2110-03-02 07:00:00       5.000000       8.000000   \n25%           2133-10-25 16:06:15      76.000000     101.000000   \n50%           2154-01-19 18:01:00      89.000000     114.000000   \n75%           2175-10-03 21:45:00     102.000000     130.000000   \nmax           2209-05-30 14:00:00     217.000000     329.000000   \nstd                           NaN      19.709705      21.900488   \n\n                 dbp            mbp  \ncount  184113.000000  184207.000000  \nmean       61.411769      77.415549  \nmin         1.000000       1.000000  \n25%        52.000000      67.000000  \n50%        60.000000      75.000000  \n75%        69.000000      86.000000  \nmax       290.000000     299.000000  \nstd        14.349584      15.897094  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dose_b_time</th>\n      <th>subject_id</th>\n      <th>charttime</th>\n      <th>heart_rate</th>\n      <th>sbp</th>\n      <th>dbp</th>\n      <th>mbp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>235790</td>\n      <td>235790.0</td>\n      <td>235790</td>\n      <td>181098.000000</td>\n      <td>184156.000000</td>\n      <td>184113.000000</td>\n      <td>184207.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2154-03-01 20:05:48.659060736</td>\n      <td>14942333.980826</td>\n      <td>2154-03-01 20:06:03.497349</td>\n      <td>90.212652</td>\n      <td>116.615189</td>\n      <td>61.411769</td>\n      <td>77.415549</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>2110-03-02 18:20:00</td>\n      <td>10004733.0</td>\n      <td>2110-03-02 07:00:00</td>\n      <td>5.000000</td>\n      <td>8.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2133-10-25 16:44:00</td>\n      <td>12429062.0</td>\n      <td>2133-10-25 16:06:15</td>\n      <td>76.000000</td>\n      <td>101.000000</td>\n      <td>52.000000</td>\n      <td>67.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2154-01-19 13:42:00</td>\n      <td>14918516.0</td>\n      <td>2154-01-19 18:01:00</td>\n      <td>89.000000</td>\n      <td>114.000000</td>\n      <td>60.000000</td>\n      <td>75.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2175-10-03 12:42:00</td>\n      <td>17509107.0</td>\n      <td>2175-10-03 21:45:00</td>\n      <td>102.000000</td>\n      <td>130.000000</td>\n      <td>69.000000</td>\n      <td>86.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2209-05-30 02:04:00</td>\n      <td>19983257.0</td>\n      <td>2209-05-30 14:00:00</td>\n      <td>217.000000</td>\n      <td>329.000000</td>\n      <td>290.000000</td>\n      <td>299.000000</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>NaN</td>\n      <td>2886914.165744</td>\n      <td>NaN</td>\n      <td>19.709705</td>\n      <td>21.900488</td>\n      <td>14.349584</td>\n      <td>15.897094</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the query\n",
    "vitals_data = results\n",
    "vitals_data.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T00:57:18.054793300Z",
     "start_time": "2023-11-03T00:57:17.963519600Z"
    }
   },
   "id": "474a0506f1d2389f"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "vitals_data.to_csv(config.out_dir / cohort_filename)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T00:57:19.845328200Z",
     "start_time": "2023-11-03T00:57:18.057785100Z"
    }
   },
   "id": "7c015c4efeb05f4"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T00:57:19.861159800Z",
     "start_time": "2023-11-03T00:57:19.847321600Z"
    }
   },
   "id": "6be30134e5cb403b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
